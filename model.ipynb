{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: unknown sort specifier\n",
      "zsh:1: unknown sort specifier\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('popular')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*FINRA API.* Access to rulebook requires paid access, source documentation [here](https://developer.finra.org/docs#query_api-finra_content-finra_rulebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read rulebook.xlsx as json\n",
    "rulebook = pd.read_excel('rulebook.xlsx', sheet_name='rulebook', engine='openpyxl')\n",
    "rulebook = rulebook.to_json(orient=\"records\")\n",
    "rulebook = json.loads(rulebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>effectiveEndDate</th>\n",
       "      <th>ruleParent</th>\n",
       "      <th>ruleTitle</th>\n",
       "      <th>detailedTopics</th>\n",
       "      <th>summaryTopics</th>\n",
       "      <th>ruleNumber</th>\n",
       "      <th>effectiveStartDate</th>\n",
       "      <th>ruleTextAscii</th>\n",
       "      <th>ruleTextHtml</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>2000. DUTIES AND CONFLICTS &gt; 2090. Know Your C...</td>\n",
       "      <td>2090. Know Your Customer</td>\n",
       "      <td>['Defined Terms within the Rule or Rule Series...</td>\n",
       "      <td>-</td>\n",
       "      <td>2090</td>\n",
       "      <td>1.341792e+12</td>\n",
       "      <td>Every member shall use reasonable diligence...</td>\n",
       "      <td>&lt;div class=\"indent_firstpara\"&gt;   &lt;span class=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>2000. DUTIES AND CONFLICTS &gt; 2090. Know Your C...</td>\n",
       "      <td>2081. Prohibited Conditions Relating to Expung...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2081</td>\n",
       "      <td>1.406678e+12</td>\n",
       "      <td>No member or associated person shall condition...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>2000. DUTIES AND CONFLICTS &gt; 2090. Know Your C...</td>\n",
       "      <td>2080. Obtaining an Order of Expungement of Cus...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2080</td>\n",
       "      <td>1.250467e+12</td>\n",
       "      <td>(a) Members or associated persons seeking to e...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>7000. CLEARING, TRANSACTION AND ORDER DATA REQ...</td>\n",
       "      <td>7110. Definitions</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(a) The term \"ADF-eligible security\" means an ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>7000. CLEARING, TRANSACTION AND ORDER DATA REQ...</td>\n",
       "      <td>7230A. Trade Report Input</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7230A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(a) Reportable Transactions Members shall comp...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  effectiveEndDate                                         ruleParent  \\\n",
       "0             None  2000. DUTIES AND CONFLICTS > 2090. Know Your C...   \n",
       "1             None  2000. DUTIES AND CONFLICTS > 2090. Know Your C...   \n",
       "2             None  2000. DUTIES AND CONFLICTS > 2090. Know Your C...   \n",
       "3             None  7000. CLEARING, TRANSACTION AND ORDER DATA REQ...   \n",
       "4             None  7000. CLEARING, TRANSACTION AND ORDER DATA REQ...   \n",
       "\n",
       "                                           ruleTitle  \\\n",
       "0                           2090. Know Your Customer   \n",
       "1  2081. Prohibited Conditions Relating to Expung...   \n",
       "2  2080. Obtaining an Order of Expungement of Cus...   \n",
       "3                                  7110. Definitions   \n",
       "4                          7230A. Trade Report Input   \n",
       "\n",
       "                                      detailedTopics summaryTopics ruleNumber  \\\n",
       "0  ['Defined Terms within the Rule or Rule Series...             -       2090   \n",
       "1                                               None          None       2081   \n",
       "2                                               None          None       2080   \n",
       "3                                               None          None       7110   \n",
       "4                                               None          None      7230A   \n",
       "\n",
       "   effectiveStartDate                                      ruleTextAscii  \\\n",
       "0        1.341792e+12     Every member shall use reasonable diligence...   \n",
       "1        1.406678e+12  No member or associated person shall condition...   \n",
       "2        1.250467e+12  (a) Members or associated persons seeking to e...   \n",
       "3                 NaN  (a) The term \"ADF-eligible security\" means an ...   \n",
       "4                 NaN  (a) Reportable Transactions Members shall comp...   \n",
       "\n",
       "                                        ruleTextHtml  \n",
       "0  <div class=\"indent_firstpara\">   <span class=\"...  \n",
       "1                                               None  \n",
       "2                                               None  \n",
       "3                                               None  \n",
       "4                                               None  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert json to pandas dataframe\n",
    "rulebook_df = pd.DataFrame(rulebook)\n",
    "\n",
    "# drop rows with null ruleTextAscii\n",
    "rulebook_df = rulebook_df.dropna(subset=['ruleTextAscii'])\n",
    "\n",
    "rulebook_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess: normalize, tokenize, stop word, stemming, lemmatization\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "def normalize(tokens):\n",
    "    normalized_tokens = [w.lower() for w in tokens]\n",
    "    return normalized_tokens\n",
    "\n",
    "def stop_words(tokens):\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    filtered_tokens = [w for w in tokens if not w in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "def stem(tokens):\n",
    "    stemmer = nltk.stem.PorterStemmer()\n",
    "    stemmed_tokens = [stemmer.stem(w) for w in tokens]\n",
    "    return stemmed_tokens\n",
    "\n",
    "def lemmatize(tokens):\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(w) for w in tokens]\n",
    "    return lemmatized_tokens\n",
    "\n",
    "def remove_punc(tokens):\n",
    "    tokens = [w for w in tokens if w.isalpha()]\n",
    "    return tokens\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = tokenize(text)\n",
    "    normalized_tokens = normalize(tokens)\n",
    "    filtered_tokens = stop_words(normalized_tokens)\n",
    "    lemmatized_tokens = lemmatize(filtered_tokens)\n",
    "    tokens = remove_punc(lemmatized_tokens)\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sentence similarity.* Use a ranking/similarity (kNN/classification) model to see which document/topic might contain the answer to the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a ranking similar model to see which rule is most similar to the input text\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_similarity_score(input_text, rulebook_df):\n",
    "\n",
    "    # preprocess rulebook\n",
    "    rulebook_df['preprocessed_ruleTextAscii'] = rulebook_df['ruleTextAscii'].apply(preprocess)\n",
    "    rulebook_df['preprocessed_ruleTextAscii'] = rulebook_df['preprocessed_ruleTextAscii'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "    # tfidf vectorizer\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(rulebook_df['preprocessed_ruleTextAscii'])\n",
    "\n",
    "    # preprocess input text\n",
    "    input_text = preprocess(input_text)\n",
    "    input_text = ' '.join(input_text)\n",
    "    input_tfidf = tfidf_vectorizer.transform([input_text])\n",
    "\n",
    "    cosine_similarities = cosine_similarity(input_tfidf, tfidf_matrix).flatten()\n",
    "\n",
    "    # append score to dataframe\n",
    "    rulebook_df['score'] = cosine_similarities\n",
    "\n",
    "    # sort by score\n",
    "    rulebook_df = rulebook_df.sort_values(by='score', ascending=False)\n",
    "\n",
    "    return rulebook_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>effectiveEndDate</th>\n",
       "      <th>ruleParent</th>\n",
       "      <th>ruleTitle</th>\n",
       "      <th>detailedTopics</th>\n",
       "      <th>summaryTopics</th>\n",
       "      <th>ruleNumber</th>\n",
       "      <th>effectiveStartDate</th>\n",
       "      <th>ruleTextAscii</th>\n",
       "      <th>ruleTextHtml</th>\n",
       "      <th>preprocessed_ruleTextAscii</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>None</td>\n",
       "      <td>2100. TRANSACTIONS WITH CUSTOMERS</td>\n",
       "      <td>2130. Approval Procedures for Day-Trading Acco...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2130</td>\n",
       "      <td>1.359936e+12</td>\n",
       "      <td>(a) No member that is promoting a day-trading ...</td>\n",
       "      <td>None</td>\n",
       "      <td>member promoting strategy directly indirectly ...</td>\n",
       "      <td>0.563338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>None</td>\n",
       "      <td>2300. SPECIAL PRODUCTS</td>\n",
       "      <td>2370. Security Futures</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2370</td>\n",
       "      <td>1.557274e+12</td>\n",
       "      <td>(a) For purposes of this Rule, the term \"secur...</td>\n",
       "      <td>None</td>\n",
       "      <td>purpose rule term security future shall defini...</td>\n",
       "      <td>0.248708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>None</td>\n",
       "      <td>2110. RECOMMENDATIONS</td>\n",
       "      <td>2111. Suitability</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2111</td>\n",
       "      <td>1.593475e+12</td>\n",
       "      <td>(a) A member or an associated person must have...</td>\n",
       "      <td>None</td>\n",
       "      <td>member associated person must reasonable basis...</td>\n",
       "      <td>0.223836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>None</td>\n",
       "      <td>2200. COMMUNICATIONS AND DISCLOSURES</td>\n",
       "      <td>2270. Day-Trading Risk Disclosure Statement</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2270</td>\n",
       "      <td>1.386115e+12</td>\n",
       "      <td>(a) Except as provided in paragraph (b), no me...</td>\n",
       "      <td>None</td>\n",
       "      <td>except provided paragraph b member promoting s...</td>\n",
       "      <td>0.223502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>None</td>\n",
       "      <td>2230. CUSTOMER ACCOUNT STATEMENTS AND CONFIRMA...</td>\n",
       "      <td>2231. Customer Account Statements</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2231</td>\n",
       "      <td>1.704067e+12</td>\n",
       "      <td>(a) General Except as otherwise provided by pa...</td>\n",
       "      <td>None</td>\n",
       "      <td>general except otherwise provided paragraph b ...</td>\n",
       "      <td>0.211602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    effectiveEndDate                                         ruleParent  \\\n",
       "59              None                  2100. TRANSACTIONS WITH CUSTOMERS   \n",
       "115             None                             2300. SPECIAL PRODUCTS   \n",
       "63              None                              2110. RECOMMENDATIONS   \n",
       "94              None               2200. COMMUNICATIONS AND DISCLOSURES   \n",
       "77              None  2230. CUSTOMER ACCOUNT STATEMENTS AND CONFIRMA...   \n",
       "\n",
       "                                             ruleTitle detailedTopics  \\\n",
       "59   2130. Approval Procedures for Day-Trading Acco...           None   \n",
       "115                             2370. Security Futures           None   \n",
       "63                                   2111. Suitability           None   \n",
       "94         2270. Day-Trading Risk Disclosure Statement           None   \n",
       "77                   2231. Customer Account Statements           None   \n",
       "\n",
       "    summaryTopics ruleNumber  effectiveStartDate  \\\n",
       "59           None       2130        1.359936e+12   \n",
       "115          None       2370        1.557274e+12   \n",
       "63           None       2111        1.593475e+12   \n",
       "94           None       2270        1.386115e+12   \n",
       "77           None       2231        1.704067e+12   \n",
       "\n",
       "                                         ruleTextAscii ruleTextHtml  \\\n",
       "59   (a) No member that is promoting a day-trading ...         None   \n",
       "115  (a) For purposes of this Rule, the term \"secur...         None   \n",
       "63   (a) A member or an associated person must have...         None   \n",
       "94   (a) Except as provided in paragraph (b), no me...         None   \n",
       "77   (a) General Except as otherwise provided by pa...         None   \n",
       "\n",
       "                            preprocessed_ruleTextAscii     score  \n",
       "59   member promoting strategy directly indirectly ...  0.563338  \n",
       "115  purpose rule term security future shall defini...  0.248708  \n",
       "63   member associated person must reasonable basis...  0.223836  \n",
       "94   except provided paragraph b member promoting s...  0.223502  \n",
       "77   general except otherwise provided paragraph b ...  0.211602  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"when should a member approve a customer's account for a day-trading strategy?\"\n",
    "\n",
    "top_rules = get_similarity_score(question, rulebook_df).head(5)\n",
    "\n",
    "top_rule_ascii = top_rules.iloc[0]['ruleTextAscii']\n",
    "\n",
    "top_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Extractive QA.* Extractive Question Answering (QA) involves directly extracting an answer from a given text, relying on the specific information contained within that text. Here, we test with Hugging Face's [BERT Squad](!https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad) model. Extractive QA models will provide answers in a verbatim manner, closely following the source material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.7363647222518921, 'start': 365, 'end': 387, 'answer': 'as soon as practicable'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# initialize the extractive QA model pipeline\n",
    "ext_qa_model = pipeline(\"question-answering\", model=\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "\n",
    "def answer_question(question, context):\n",
    "    # split the context into chunks\n",
    "    max_chunk_size = 512 - len(question)  # adjust based on the length of the question\n",
    "    context_chunks = [context[i:i+max_chunk_size] for i in range(0, len(context), max_chunk_size)]\n",
    "    \n",
    "    answers = []\n",
    "    for chunk in context_chunks:\n",
    "        # perform question answering on each chunk\n",
    "        answer = ext_qa_model(question=question, context=chunk)\n",
    "        answers.append(answer)\n",
    "    \n",
    "    # select the best answer (you can customize this part to choose the best answer based on your criteria, e.g., highest score)\n",
    "    best_answer = max(answers, key=lambda x: x['score'])\n",
    "    return best_answer\n",
    "\n",
    "print(answer_question(question, top_rule_ascii))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Open Generative QA.*  Generative QA generates free text directly based on the context. This is a form of [text generation](!https://huggingface.co/tasks/text-generation), common models include GPT2, Llama, and Google's FLAN. Generative QA can answer questions in full sentences, as opposed to the Extractive QA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"customer has provided the member with the risk disclosure statement set forth in Rule 2270 and has: (1) approved the customer's account for a day-trading strategy in accordance with the procedures set forth in paragraph (b) and prepared a record setting forth the basis on which the member has approved the customer's account; or (2) received from the customer a written agreement that the customer does not\"]\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# initialize\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\")\n",
    "max_new_tokens = 150\n",
    "\n",
    "max_length = 512  # max length for T5 input sequences\n",
    "input_text = question + \" \" + top_rule_ascii  # combine question and rules into a single string\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", truncation=True, max_length=max_length)\n",
    "\n",
    "# Generate the output\n",
    "outputs = model.generate(input_ids, max_length=max_new_tokens)\n",
    "decoded_output = tokenizer.decode(outputs[0]).replace(\"<pad>\", \"\").strip().replace(\"</s>\", \"\")\n",
    "\n",
    "# summarize the output\n",
    "def summarize(input_text):\n",
    "    summ_results = []\n",
    "    summarizer = pipeline(\"summarization\", model=\"google/pegasus-xsum\")\n",
    "    for i in summarizer(input_text, min_length=20, max_length=80, truncation=True):\n",
    "        summ_results.append(i['summary_text'])\n",
    "    return summ_results \n",
    "\n",
    "decoded_output = summarize(decoded_output)\n",
    "\n",
    "print(decoded_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
